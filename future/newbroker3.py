#!/usr/bin/env python
# -*-coding: utf8-*-
# newbroker.py
'''
One root process (like broker) starts two threads.
- 1: start all jobs ("StartJobs") from a list of instructions until 
    none remain, then sleep a short time.
- 2: finish all jobs ("FinishJobs") running until none remain, 
    then sleep a short time.  
Each case is a separate multiprocessing task (like listactor) that receives 
    a list of commands to execute.  
  A single listactor-like case itself a multiprocessing job 
    (mp jobs 3 thru nParallel).
    The case runs a sequence of subprocess jobs, one per command, 
      collects output.
      Case writes logfile where specified, returns list of output lines.
- For each command in the list, the subprocess job executes 
    that command via the shell and receives its stdout as a string, 
    which is splits into a list of lines.
- The multiprocessing job (listactor) appends the outputs of the several 
    commands, each output a list of lines, into a list, and queues 
    that list back to the single parent (broker). 
'''

import multiprocessing
import subprocess 
import threading
import time
import sys
import collections
import re
import itertools
import datetime
import os
from NewTrace import NTRC, ntrace, ntracef


# Named tuples:
# Job process ID and output queue.
tJob = collections.namedtuple("tJob", "procid")
# Line returned from a single command
tLineOut = collections.namedtuple("tLineOut", 
            "callstatus cmdstatus casenr linenr ltext ")
# List of lines returned from list of commands
tLinesOut = collections.namedtuple("tLinesOut", "procname, listoflists")
# Sadistics on how many times we waited for something
tWaitStats = collections.namedtuple("tWaitStats", "ncases slot done")


# ==================== subprocess user: do one line ====================

# f n D o O n e L i n e 
@ntracef("DO1L")
def fntDoOneLine(mysLine, mynProc, mynLine):
    """Execute one command.  
    
    Input: single line of command.  
    Output: tuple of the (Popen PIPE return code, command return code, list
     of output lines as strings.
     Input lines and the first line of output blocks have timestamps;
     other lines in output blocks are indented with spaces.  
    """
    sTimeBegin = fnsGetTimestamp()
    proc = (subprocess.Popen(mysLine
        , stdout=subprocess.PIPE
        , close_fds=True            # The default anyway, I think.  
        , stderr=subprocess.DEVNULL
        , universal_newlines=True
        , shell=True)
        )
    (sProcOut, sProcErr) = proc.communicate()
    proc.stdout.close()
    if not sProcErr: sProcErr = ""
    sTimeEnd = fnsGetTimestamp()
    
    # Format lines for output by timestamping or indenting each line.  
    sOut = ("-"*len(sTimeBegin) + "\n"
            + sTimeBegin + "  " + "$ " + mysLine + "\n")
    lTmpOut1 = sProcOut.rstrip().split("\n")
    lTmpOut2 = [fnsStampLine(sTimeEnd, sLine, (i==0))
                    for i,sLine in enumerate(lTmpOut1)]
    sOut += "\n".join(lTmpOut2)
    sOut += sProcErr.rstrip()
    
    # Collect and return everything to caller.  
    nCmdStat = "n/a - RBL"
    nReturnCode = proc.returncode
    lOut = sOut.split("\n")
    NTRC.ntracef(4, "DO1L", "proc DoOneLine case|%s| line|%s| "
                "sline|%s| lResult|%s|" 
                % (mynProc, mynLine, mysLine, lOut))
    
    return(tLineOut(callstatus=nReturnCode, cmdstatus=nCmdStat
            , linenr=mynLine, casenr=mynProc, ltext=lOut))


# ==================== multiprocessing: DoOneCase ====================

# f n t D o O n e C a s e 
@ntracef("DO1")
def fntDoOneCase(mytInstruction, qToUse):
    """Input: list of instructions generated by the broker for this case; 
     multiprocessing queue through which to report results.
    
    Remove blanks, comments, etc., from the instructions.  Each line that
     is not blank or comment is a command to be executed.  Blanks and 
     comments are written directly into the output.

    Output: list of commands and their output, sent to the supplied queue.
     The text will also be written to a log file for the case.  
    
    This function will be a multiprocessing external process.
    """
    sWhoami = multiprocessing.current_process().name
    NTRC.ntracef(3, "DO1", "proc procname|%s|" % (sWhoami))
    nProc = fnsGetProcessNumber(sWhoami)
    lResults = []                   # list of strings

    # Unpack instructions.
    lInstruction = mytInstruction.cmdlist
    (sLogfileDir, sLogfileName) = (mytInstruction.logdir
                                , mytInstruction.logname)

    # Process all lines of instructions and collect results.  
    for nLine, sLine in enumerate(lInstruction):
        if fnbDoNotIgnoreLine(sLine):
            # Genuine line; execute and collect answer line(s).  
            tAnswer = fntDoOneLine(sLine, nProc, nLine)
            (nRtn, nErr, lResult) = (tAnswer.callstatus
                                    , tAnswer.cmdstatus
                                    , tAnswer.ltext)
            lResults.extend(lResult)
            NTRC.ntracef(4, "DO1", "proc DoOneCase case|%s| line|%s| "
                        "lResult|%s|" 
                        % (nProc, nLine, lResult))
        else:
            # Comment or blank line; just append to results.
            lResults.extend([("-"*len(fnsGetTimestamp()))
                            , (fnsGetTimestamp() + "  " + sLine)])
            NTRC.ntracef(4, "DO1", "proc DoOneCase case|%s| line|%s| "
                        "comment|%s|" 
                        % (nProc, nLine, sLine))
    fnWriteLogFile(nProc, (lResults), sLogfileDir, sLogfileName)

    lPrefix = [("BEGIN results from " + sWhoami)]
    lSuffix = [("ENDOF results from " + sWhoami)]
    lResultsToSee = ['\n'] + lPrefix + lResults + lSuffix + ['\n']
    tAnswers = tLinesOut(procname=sWhoami, listoflists=lResultsToSee)
    qToUse.put(tAnswers)
    qToUse.close()
    return (tAnswers)


# f n W r i t e L o g F i l e 
@ntracef("DO1")
def fnWriteLogFile(mynProc, mylContents, mysFileDir, mysFileName):
    sFullName = mysFileDir + "/" + mysFileName
    sContents = '\n'.join(mylContents)
    with (open(sFullName, "w")) as fhOut:
        print(sContents, file=fhOut)

# Debug version of same: write only every tenth log file.
if not (os.getenv("DEBUG", "") == ""):
    @ntracef("DO1")
    def fnWriteLogFile(mynProc, mylContents, mysFileName):
        sContents = '\n'.join(mylContents)
        if fnIntPlease(mynProc) % 10 == 0:
            with (open(mysFileName, "w")) as fhOut:
                print(sContents, file=fhOut)


# ==================== Global Data ====================

class CGlobal():
    """Data that is global, to this function, at least, so that it can
    shared between threads.  
    """
    ltJobs = list()     # Job numbers or None
    lockJobList = None  # 
    dId2Proc = dict()   # Map job number -> process object
    dId2Queue = dict()  # Map job number -> queue object
    nParallel = 4       # Limit on jobs running in parallel (on separate CPUs)
    bThatsAllFolks = False  # All cases done, ran out of instructions.
    nCasesTotal = 0     # Nr of instructions total, all started.
    nCasesStarted = 0   # How many cases started so far.  #DEBUG
    nCasesDone = 0      # How many cases done (finished) so far. #DEBUG
    llsFullOutput = list()  # Output for all test cases.
    nCases = 1          # DEBUG
    nWaitedForSlot = 0  # DEBUG
    nWaitedForDone = 0  # DEBUG
    bDebugPrint = False # Print output of all jobs?


# ==================== multiprocessing: RunEverything ====================

def fntRunEverything(mygl, itlsInstructions, nWaitMsec, nWaitHowMany):
    '''Start an async job for each case.  Limit number of concurrent jobs
    to the size of the ltJobs vector.  
    When a job completes, ship its output upline and remove it from 
    the active lists.  
    
    Two separate threads:
    - Wait for an empty slot; get an instruction, start an async job.
    - Wait for an active job to complete and remove it from lists.  
    '''
    # Fill the list of jobs with empties.
    for i in range(mygl.nParallel + 1): mygl.ltJobs.append(None)
    mygl.lockJobList = threading.Lock()
    mygl.lockPrint = threading.Lock()

    # Create new threads
    NTRC.ntracef(5, "RUN", "proc make thread instances")
    thrStart = CStartAllCases(mygl, mygl.nCoreTimer, mygl.nStuckLimit
                            , itlsInstructions, )
    thrEnd = CEndAllCases(mygl, mygl.nCoreTimer, )
    mygl.llsFullOutput = [["",""]]
    thrStart.start()
    thrEnd.start()
    
    # Wait until all jobs have started and finished.
    thrStart.join()     # Runs out of instructions.
    thrEnd.join()       # Runs out of finished jobs.  
    return tWaitStats(ncases=mygl.nCasesDone
                , slot=mygl.nWaitedForSlot, done=mygl.nWaitedForDone)


# ==================== thread: DoAllCases ====================

class CStartAllCases(threading.Thread):
    """pseudocode:
    arg gives list of instructions,
     each instruction is list of command lines
    foreach instruction in list
      wait for opening
      create queue for result
      create process to do instruction
      append (process,queue) to job list
    """


    #@ntracef("STRT")
    def __init__(self, mygl 
                , mynWaitMsec, mynWaitHowMany
                , myitlsInstructions
                ):
        threading.Thread.__init__(self)
        self.gl = mygl
        self.nWaitMsec = mynWaitMsec
        self.nWaitHowMany = mynWaitHowMany
        self.nCounter = itertools.count(1)
        self.nProcess = 0
        self.itlsInstructions = myitlsInstructions
        NTRC.ntracef(2, "STRT", "exit init gl|%s| instrs|%s|" 
                % (self.gl, self.itlsInstructions))


    @ntracef("STRT")
    def run(self):
        while (fnbWaitForOpening(self.gl, self.nWaitMsec, self.nWaitHowMany)
                ):
            NTRC.ntracef(3, "STRT", "proc doallcases slot avail for case|%s|" 
                        % (self.nProcess))

            # L O C K 
            with self.gl.lockJobList:
                # Find an empty slot in the jobs list.
                lEmptySlots = [idx for (idx,x) in enumerate(self.gl.ltJobs) 
                                if not x]
                assert len(lEmptySlots) > 0, ("Supposed to be an empty slot"
                            "for new case, but I can\'t find one.")
                idxEmpty = lEmptySlots[0]

                # Instruction list for this job.
                #  If the list is empty, then we are done here.
                # itlInstructions is an iterator that produces a list of
                #  instructions strings for each next().  
                # BEWARE: instruction list might be a generator, 
                #  cannot test length.  
                # StopIteration for generator or iterator; IndexError for dunno.
                try:
                    tOneInstr = next(self.itlsInstructions)
                    NTRC.ntracef(3, "STRT", "proc instr|%s|" % (repr(tOneInstr)))
                    lLines, sLogFilename = tOneInstr.cmdlist, tOneInstr.logname
                    dInstr, sRunId = tOneInstr.casedict, tOneInstr.runid
                except(StopIteration, IndexError):
                    self.gl.bThatsAllFolks = True
                    self.gl.nCasesTotal = self.gl.nCasesStarted
                    NTRC.ntracef(1, "STRT", "proc startall "
                                "exhausted instructions nprocess|%s|" 
                                % (self.nProcess))
                    break

                # Create resources for the job.        
                qOut = multiprocessing.Queue()
                nJob = next(self.nCounter)
                with self.gl.lockPrint:
                    NTRC.ntracef(0, "STRT", "proc case|%s| start" % (nJob))
                proc = multiprocessing.Process(target=fntDoOneCase
                                , args=(tOneInstr, qOut)
                                )
                tThisJob = tJob(procid=nJob, )

                # Save job in empty slot of list, and save dict
                #  entries to get proc and queue.
                self.gl.dId2Proc[nJob] = proc
                self.gl.dId2Queue[nJob] = qOut
                # Save job info in jobs list.
                self.gl.ltJobs[idxEmpty] = tThisJob
                NTRC.ntracef(3, "STRT", "proc startall go slot|%s| njob|%s|" 
                            % (idxEmpty, nJob))

                proc.start()
                self.nProcess += 1
                self.gl.nCasesStarted += 1
            # E N D L O C K 

# ==================== thread: EndAllCases ====================

class CEndAllCases(threading.Thread):
    """pseudocode:
    while forever
        get list of (job,queue) *shared data*
        while noempty, foreach in list of job.notalive
            join job to make sure it's dead
            empty queue
            append output to big string
            pop job from list *shared data*
        if empty
            if instruction list empty
                return big string
            else
                wait a few milliseconds
    """

    #@ntracef("END")
    def __init__(self, mygl, mynWaitMsec):
        threading.Thread.__init__(self)
        self.gl = mygl
        self.nWaitMsec = mynWaitMsec
        self.llsFullOutput = list()
        NTRC.ntracef(2, "END", "exit init gl|%s| wait|%s|" 
                    % (self.gl, self.nWaitMsec))


    @ntracef("END")
    def run(self):
        NTRC.ntracef(5, "END", "proc run ltJobs|%s|" % (self.gl.ltJobs))
        nCasesDone = 0
        self.gl.nWaitedForDone = 0
        while True:
            # L O C K 
            with self.gl.lockJobList:
                NTRC.ntracef(3, "END", "proc ltJobs|%s|" % (self.gl.ltJobs))
                ltActiveJobs = [(idx,tJob) for idx,tJob in 
                                enumerate(self.gl.ltJobs) if tJob]
                NTRC.ntracef(3, "END", "proc ltActiveJobs|%s|" % (ltActiveJobs))
                for idxtJob in ltActiveJobs:
                    idx,tJob = idxtJob
                    nJob = tJob.procid
                    proc = self.gl.dId2Proc[nJob]
                    if not proc.is_alive():
                        NTRC.ntracef(3, "END", "proc endall found done "
                                    "ltJobs[%s]=procid|%s|=|%s| alive?|%s|" 
                                    % (idx, nJob, proc, proc.is_alive()))
                        # Job listed as still baking but reports that it is done.
                        # Wait until it is fully baked.
                        proc.join()
                        with self.gl.lockPrint:
                            NTRC.ntracef(0, "END", "proc case|%s| end" 
                                        % (nJob))
                        # Get its output for the full debug list.
                        queue = self.gl.dId2Queue[nJob]
                        lQOutput = []
                        while not queue.empty():
                            lLinesOut = queue.get().listoflists
                            lQOutput.append(lLinesOut)
                        queue.close()
                        if self.gl.bDebugPrint:
                            NTRC.ntracef(5, "END", "proc lQOutput from q|%s|" 
                                            % (lQOutput))
                            self.llsFullOutput.extend(lQOutput)
                            NTRC.ntracef(5, "END", "proc lOutput from q|%s|" 
                                        % (self.llsFullOutput))
                        # Remove job from active list and Id-dicts.
                        # If the queue objects are still in the dId2Queue dict,
                        #  the pipe remains open, oops.  
                        self.gl.ltJobs[idx] = None
                        self.gl.dId2Proc.pop(nJob)
                        self.gl.dId2Queue.pop(nJob)
                        nCasesDone += 1
                        self.gl.nCasesDone += 1
                        NTRC.ntracef(3, "STRT", "proc job completed ndone|%s|" 
                                    % (self.gl.nCasesDone))

                NTRC.ntracef(3, "END", "proc end for-activejobs1"
                            " thatsall?|%s| ndone|%s| nstarted|%s|" 
                            % (self.gl.bThatsAllFolks
                            , self.gl.nCasesDone, self.gl.nCasesStarted))
                if (self.gl.bThatsAllFolks 
                    and self.gl.nCasesDone == self.gl.nCasesTotal):
                    break
                else:
                    self.gl.nWaitedForDone += 1
                    NTRC.ntracef(3, "END", "proc end for-activejobs2 wait, "
                                "ndone|%s| nwaits|%s|" 
                                % (nCasesDone, self.gl.nWaitedForDone))
                    time.sleep(self.nWaitMsec / 1000.0)
                    continue
            # E N D L O C K 

        # llsFullOutput is a list of list of strings, where
        #  the inner list is lines output from commands for
        #  one job, more or less, with prefix and suffix 
        #  and comments, too.
        # Paste the whole thing together into a yuge list of lines.
        if self.gl.bDebugPrint:
            sFullOutput = ""
            for lJobOut in self.llsFullOutput:
                sJobOut = "\n".join(lJobOut)
                sFullOutput += sJobOut
            NTRC.ntracef(5, "END", "proc sFullOutput|%s|" % (sFullOutput))


# ==================== utilities ====================

# f n b D o N o t I g n o r e L i n e 
def fnbDoNotIgnoreLine(mysLine):
    '''
    True if not a comment or blank line.
    '''
    # Ignore comment and blank lines, but take all others.
    return (not re.match("^\s*#", mysLine)) and (not re.match("^\s*$", mysLine))


# f n I n t P l e a s e 
def fnIntPlease(mysIn):
    try:
        val = int(mysIn)
    except ValueError:
        val = mysIn
    return val


# f n n H o w M a n y A l i v e 
@ntracef("MANY", level=5)
def fnnHowManyAlive(gl):
    '''How many empty slots in the jobs list?
    The criterion is just empty (=None) vs anything else.
    '''
    nAlive = len([1 for tJob in gl.ltJobs if tJob])
    return nAlive


# f n b W a i t F o r O p e n i n g 
@ntracef("WAIT")
def fnbWaitForOpening(gl, mynWaitTimeMsec, mynWaitMax):
    '''How many active jobs?  If maxed out, wait for an empty slot 
    and try again.
    '''
    nWait = mynWaitMax
    while nWait:
        nAlive = fnnHowManyAlive(gl)
        if nAlive < gl.nParallel:
            break
        else:
            nWait -= 1
            gl.nWaitedForSlot += 1
            if gl.bDebugPrint:
                print(".", end='')          # DEBUG
            time.sleep(mynWaitTimeMsec / 1000.0)
            NTRC.ntracef(5, "WAIT", "proc waitforopening timesleft|%s| "
                        "nwaited|%s|" 
                        % (nWait, gl.nWaitedForSlot))

    # Have we waited too long for an opening?
    if nWait <= 0:
        raise ValueError("Waited too long for empty job slot.")
    else:
        return (nWait > 0)


# f n s G e t P r o c e s s N u m b e r 
def fnsGetProcessNumber(mysProcName):
    '''Extract the process number, which is the same as the case number
    in this case, so we can use its abbreviated form in logs and traces.
    '''
    sProcNum = re.match("Process-(\d+)", mysProcName).group(1)
    return sProcNum if sProcNum else ""


# f n s G e t T i m e s t a m p 
def fnsGetTimestamp():
    '''Return timestamp with milliseconds.
    '''
    return datetime.datetime.now().strftime('%Y%m%d_%H%M%S.%f')[:-3]
#    return datetime.datetime.now().strftime('%Y%m%d_%H%M%S')   # without msec


# f n s S t a m p L i n e 
def fnsStampLine(mysStamp, mysLine, mybFirstLine):
    """To indent paras of lines where the timestamp appears only
    on the first line, blanks to indent all the others.  
    """
    if mybFirstLine:
        return fnsGetTimestamp() + "  " + mysLine
    else:
        return " "*len(fnsGetTimestamp()) + "  " + mysLine


# ==================== in main process ====================

# E n t r y   p o i n t 
if __name__ == "__main__":

    # ==================== m a i n N e w B r o k e r ====================
    @ntrace
    def mainNewBroker(gl):

        NTRC.ntrace(3, "proc params ncases|%s| nparallel|%s| "
                        "nwaitmsec|%s| nwaitmany|%s|" 
                    % (gl.nCases, gl.nParallel, gl.nWaitMsec, gl.nWaitHowMany))
        
        # Main loop
        
        # Create list of instructions.  Each instruction is a list of 
        #  command strings.
        lLinesTemp = [sLine.lstrip() 
                    for sLine in sTempListOfCommands.split('\n')
                    ]
        # And make a list of instructions for each case.
        llsInstructionsTemp =  [lLinesTemp] * gl.nCases

        tTmp = fnRunEverything(gl, iter(llsInstructionsTemp)
                            , gl.nWaitMsec, gl.nWaitHowMany)
        (gl.nWaitedForSlot, gl.nWaitedForDone) = (tTmp.slot, tTmp.done)
        return []   # used to be llOut in early proto


    # m a i n 
    def main(gl):
        NTRC.ntrace(0, "Starting...")
        tStart = datetime.datetime.now()
        llFullOutput = mainNewBroker(gl)

        if gl.bDebugPrint:
            # Print all the crap that comes back.  
            print("---------begin cases----------")
            for lCase in llFullOutput:
                sCaseOut = ""
                NTRC.ntrace(3, "proc fromq lCase|%s|" % (lCase))
                sCaseOut = '\n'.join(lCase)
                print(sCaseOut)
                print("--------------")
            print("---------end cases----------")
        NTRC.ntrace(0, "Finished nWaitedForSlot|%s| nWaitedForDone|%s|" 
                    % (gl.nWaitedForSlot, gl.nWaitedForDone))
        tEnd = datetime.datetime.now()
        tDif = tEnd - tStart
        tDifMuSec = float((tDif.seconds * 1E6) + tDif.microseconds)
        NTRC.ntrace(0, "Time total|%.3f|sec cases|%s| parallel|%s| "
                    "per case|%.0f|msec" 
                    % (tDifMuSec/1E6, gl.nCases, gl.nParallel,
                    tDifMuSec/gl.nCases/1E3))


    gl = CGlobal()      # Instantiate global data region.  

    # Get CLI args or their default values.
    '''
    argv[1] = total number of cases to run; default 20.
    argv[2] = max number to run simultaneously; default 8.
    argv[3] = sleep interval in loop waiting for open process slot; 
                default 50 (msec).
    argv[4] = max number of times to sleep waiting for an open process slot; 
                default = 100.
    argv[5] = if present, causes debug printing of all the job output.
    '''
    gl.nCases = 20 
    gl.nParallel = 8
    gl.nWaitMsec = 50
    gl.nWaitHowMany = 10000
    nArgs = len(sys.argv)
    if nArgs > 1: gl.nCases = int(sys.argv[1]) 
    if nArgs > 2: gl.nParallel = int(sys.argv[2]) 
    if nArgs > 3: gl.nWaitMsec = int(sys.argv[3]) 
    if nArgs > 4: gl.nWaitHowMany = int(sys.argv[4]) 
    if nArgs > 5: gl.bDebugPrint = True

    """ Temp hack to make instructions for debugging.
    """
    try:
        with open("instructions.txt", "r") as fhIn:
            sTempListOfCommands = fhIn.read()
    except FileNotFoundError:
        # Cheap version.
        sTempListOfCommands = '''
            date +%Y%m%d_%H%M%S.%3N
            # this is comment 1
            ls | head -3
            pwd
            # this is comment 2
            
            # and a blank line before and after this one
            
            python3 -V
            python3 fib.py 35       # spend some cpu time
            cat /proc/version
            cat /proc/cpuinfo | grep processor |wc -l   
            ps | grep python | grep -v grep
            date +%Y%m%d_%H%M%S.%3N
        '''
        # Really cheap version.  
        sTempListOfCommands = '''
            date +%Y%m%d_%H%M%S.%3N
        '''

    sys.exit(main(gl))


# Edit history:
# 20181105  RBL First version that actually works, yay.  Finally remembered
#                to remove references to the queue pipes from the ID-dict
#                so that now the pipe files get closed.  
# 20181106  RBL Add nWaitedForDone to the end stats.
#               Add timestamps to log file for all lines including comments.
# 20181110  RBL Fold RunAll into the root process; it would be too hard to 
#                pass the instruction generator through pipes.  
# 20181111  RBL Clean up references to gl, which caused some things not
#                to be accounted properly.  
# 
# 

#END
