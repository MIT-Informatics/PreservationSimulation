TO MAKE MULTIPLE COPIES OF A COLLECTION: Notes

                        RBLandau 20140304
                        after call with Micah 0900


Client distributes collection to all servers available at the required quality level.  For the moment, quality level matches the value level of the collection.  
- quality rating for service comes from service info

Client sends out copy of entire collection to multiple libs
- for a collection of some value, find the set of servers of that value; use all servers at the right quality level.

Client creates collection
- get distribution rules for this type of collection
- find servers at right quality level
- for each suitable server send collection to server as individual docs
- add server id to list for this collection
- for each document add doc id to list for this server
- count copies of doc stored on servers, changes with failures and repairs

Client maintains list of copies of each collection
  - client sends collection to lib, adds lib to list of copies
  - for each copy, maintain list of docs in that copy
  - if collection fails at lib, client removes lib from list of copies and resends; re-send re-adds lib to list, now at the end.
  - if doc fails at lib, collection removes from its copy and resends

-----------------

Change name from "library" to "server"
- less freighted with assumptions
- then server can have multiple "services" or "sites"

Change "client" to "owner" too?

Concentrate on one client, one collection, multiple servers.  
- Multiple servers will eventually need multiple sites with some different characteristics, such as physical failure rates by geography. 
- A single vendor such as Amazon AWS does offer multiple services with different failure characteristics.  

Documents:
- PDF, small MB range
- static pic, slightly larger but still small MB range
- video, small GB range
- empirical data not available
- add sensitivity to small failures in near future

Scale factors, for now:
- okay to keep doc size click in MB
- okay to keep sector failure click as 1, i.e., 1MB
- okay to keep time tick as hour (this makes minimum repair time long)

Sector failures become hidden failures, wait for audit to reveal them

Distributions of document size:
- bimodal or multimodal
- trimmed Gaussian with small variance
- mix two, maybe in separate collections, maybe in one
- maybe a research library distribution overall is exponential, but a single collection is more nearly uniform
- [Maybe emprically modeled distribution would be easier to deal with, done in, say, twenty bins or more, uniform within those bins.  Five-percent-iles seems reasonable; single percentiles seems excessive.  Easier to convince people that one can model whatever they think their collection looks like.]
- fancy calculation for doc size distn is a burden only when initially populating the simulation, not during runtime 

Repair simple 
- push to server or server will pull another copy
- short-term: audit remaining copies until you find a good one to give to server.  That process might find more dead copies.  
- longer-term: audit remaining copies.  Need to find a consensus copy.  
- in both these cases, if there is not a sufficient number of good copies left, then the document is irretrievably lost.  


Repair speed depends on bandwidth 
- assume 1GB/hour
- well, maybe 1Mb/sec, which translates to 5MB/min, 300MB/hour
- [Seems low to me; I get 25Mb from my el cheapo cable modem from Comcast midday; will 96% of that be consumed by other business?  Auditing is always done off-hours, right?  Could be rate-limited, I suppose.  On the other hand, we might have to change the tick size from hour to minute and the doc size from MB to KB to be more realistic.  That will make the numbers less readable, but we can easily do that later if needed.]

Auditing:
- Client audits a collection at a time.  (Later, a random subset of a collection sampled without replacement.  At least for large collections.)
- Audit round-robin through collections.  
- Audit asks for some proof of each document in turn, one at a time.  If result is bad, initiate repair for that doc.  
- When audit complete, wait for some time interval and then initiate the next audit.  
- cost of auditing << repair cost, where cost = time/bandwidth
- assume 1-2 orders of magnitude less
- short-term, a document either exists or doesn't; a shelf failure or hidden failure destroys that copy of the document.  

Logging: 
- collection placed
- initial document placement is too fine-grained and verbose
- failures at server destroy or damage docs
- hidden failues at server corrupt doc
- how many docs left in remote collection after failure, maybe shelf
- how many copies left of doc in all remote sites; can calculate on the fly if failure is a rare event
- shelf fail destroys all docs
- audit reveals hidden failure, get a new copy, repair
- all copies of document lost = document failure
- n-events in general, for judging lengths of longer simulations

----------

Repair

Shelf failure
- Shelf reports Client:DocDiedOnServer for every doc on the shelf.
- Reports may go to different clients.
- Client tries to find a valid copy of doc.
- First version: don't search; assume the client's version is okay.
- Second version: client audits copies of doc on all servers.  If there is a valid one anywhere, proceed with repair.  If there is none, the document has failed.  (Equivalent to client keeping fixity info only but not a copy of doc.)
- Third version: client audits copies of doc on all servers.  If there are enough valid copies to form a consensus, then proceed with repair.  
- During audit, any failure discovered on a server is equivalent to reporting DocDiedOnServer.  
- During audit, if there is no valid copy of doc on any server, then the doc has failed permanently and is lost.  

On Client
- Shelf failure calls doc died on server for all docs on shelf.
- Server failure calls doc died on server for all docs on all shelves of the server.  
- Find valid doc.
- Audit doc on all servers.
- Doc died on server.  
- Repair doc to server.  

On Server
- Report shelf fail.
- Report doc fail.  
- Report server fail.  

Shelf:mShelfFailed
Client:mDocFailedOnServer
Shelf:mDocDied
Server:mServerFailed
Client:mDocFindValidCopy
Client:mDocAuditAllDocsOnServer
Client:mDocAuditOnAllServers
Client:mDocAuditOnServer
Client:mDocRepairOnServer
Client:mDocPermanentFailure

-----------------

Failure Rates

What is the rate of failure of a single sector?

- Failure for sector on shelf is sector rate times size of shelf.  Then - For convenience, sector = megabyte.  If we need to sharpen this, then we'll change the size distributions of documents to correct the scale.  
- For convenience, a year = 10,000 hours.  
- Example: A sector suffers a failure every ten years = 100,000 hours.  Shelf contains 10,000 sectors.  Failure rate for some sector within a shelf is sectors per hour (1E-05) times number of sectors in a shelf (1E+04) yields 0.1 sector failure per hour, or one sector in the shelf per ten hours.  Yikes, that seems way high.  
- Example: failure per sector 1E-06; shelf 1E+04 sectors. Failure of some sector within that shelf is 1E-02 sectors per hour, one sector every hundred hours.  Better.  



